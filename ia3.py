# -*- coding: utf-8 -*-
"""IA3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AYZKYKdBp4l2CtFQLrsGh5Tef0KgmeeJ

First let's import the packages needed for this assignment.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn import svm
from sklearn.naive_bayes import MultinomialNB

from sklearn.model_selection import GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

import seaborn as sns

from google.colab import drive
drive.mount('/content/gdrive')

train_path = '/content/gdrive/My Drive/AI534/IA3-train.csv'
val_path = '/content/gdrive/My Drive/AI534/IA3-dev.csv'
train_data = pd.read_csv(train_path)
val_data = pd.read_csv(val_path)

negative = train_data[train_data['sentiment'] == 0]['text']
positive = train_data[train_data['sentiment'] == 1]['text']

vectorizer = TfidfVectorizer(stop_words='english')
#All tweets
tfidf_matrix_all = vectorizer.fit_transform(train_data['text'])
feature_names_all = vectorizer.get_feature_names_out()

#Positive Tweets
tfidf_matrix_positive = vectorizer.transform(positive)
feature_names_positive = vectorizer.get_feature_names_out()

#negative tweets
tfidf_matrix_negative = vectorizer.transform(negative)
feature_names_negative = vectorizer.get_feature_names_out()

# Find words used in both positive and negative responses
positive_words = [feature_names_all[col] for col in tfidf_matrix_positive.nonzero()[1]]
negative_words = [feature_names_all[col] for col in tfidf_matrix_negative.nonzero()[1]]

# Find words in both positive and negative responses
common_words = set(positive_words).intersection(set(negative_words))

# Filter feature names for positive and negative responses
positive_words = list(set(positive_words) - common_words)
negative_words = list(set(negative_words) - common_words)

# Print results
print("Words in Positive Responses:")
print(positive_words)

print("\nWords in Negative Responses:")
print(negative_words)

print("\nWords in Both Positive and Negative Responses:")
print(list(common_words))

X_train = train_data['text']
y_train = train_data['sentiment']

# Separate features (X_val) and target variable (y_val) for validation
X_val = val_data['text']
y_val = val_data['sentiment']

# Use TfidfVectorizer to convert text data to TF-IDF features
vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_val_tfidf = vectorizer.transform(X_val)

# Define the SVM model
svm_model = SVC(kernel='linear')

# Define the hyperparameter grid for grid search
param_grid = {'C': [10**i for i in range(-3, 4)]}

# Perform grid search with cross-validation based on validation accuracy
grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy', return_train_score = True)
grid_search.fit(X_train_tfidf, y_train)

# Get the best hyperparameters
best_params = grid_search.best_params_
best_c = best_params['C']

# Train the SVM model with the best hyperparameters on the entire training set
final_svm_model = SVC(kernel='linear', C=best_c)
final_svm_model.fit(X_train_tfidf, y_train)

# Record the total number of support vectors
total_support_vectors = final_svm_model.n_support_.sum()

# Validate the model on the validation set
y_train_pred = final_svm_model.predict(X_train_tfidf)
y_val_pred = final_svm_model.predict(X_val_tfidf)

# Evaluate the validation accuracy
train_accuracy = accuracy_score(y_train,y_train_pred)
val_accuracy = accuracy_score(y_val, y_val_pred)

print(f"Best C: {best_c}")
print(f"Total Support Vectors: {total_support_vectors}")
print(f"Train Accuracy: {train_accuracy:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

results = pd.DataFrame(grid_search.cv_results_)
print(results)

# Plot of training and validation accuracy vs log(C)
plt.figure(figsize=(10, 6))
plt.semilogx(param_grid['C'], results['mean_test_score'], label='Validation Accuracy', marker='o')
plt.semilogx(param_grid['C'], results['mean_train_score'], label='Train Accuracy', marker='o')

plt.title('Accuracy vs. C')
plt.xlabel('C (log scale)')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Boundry Expansion
# Copy code but change grid search
param_grid = {'C': [10**i for i in range(-5, 6)]}

grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy', return_train_score = True)
grid_search.fit(X_train_tfidf, y_train)

best_params = grid_search.best_params_
best_c = best_params['C']

final_svm_model = SVC(kernel='linear', C=best_c)
final_svm_model.fit(X_train_tfidf, y_train)

total_support_vectors = final_svm_model.n_support_.sum()

y_train_pred = final_svm_model.predict(X_train_tfidf)
y_val_pred = final_svm_model.predict(X_val_tfidf)

train_accuracy = accuracy_score(y_train,y_train_pred)
val_accuracy = accuracy_score(y_val, y_val_pred)

print(f"Best C: {best_c}")
print(f"Total Support Vectors: {total_support_vectors}")
print(f"Train Accuracy: {train_accuracy:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

## Grid Refinement for Central Optima (1)

# Copy code but change grid search
param_grid = {'C': [.5,1,1.5,2,3,5]}

grid_search = GridSearchCV(svm_model, param_grid, cv=3, scoring='accuracy', return_train_score = True)
grid_search.fit(X_train_tfidf, y_train)

best_params = grid_search.best_params_
best_c = best_params['C']

final_svm_model = SVC(kernel='linear', C=best_c)
final_svm_model.fit(X_train_tfidf, y_train)

total_support_vectors = final_svm_model.n_support_.sum()

y_train_pred = final_svm_model.predict(X_train_tfidf)
y_val_pred = final_svm_model.predict(X_val_tfidf)

train_accuracy = accuracy_score(y_train,y_train_pred)
val_accuracy = accuracy_score(y_val, y_val_pred)

print(f"Best C: {best_c}")
print(f"Total Support Vectors: {total_support_vectors}")
print(f"Train Accuracy: {train_accuracy:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

# Define the SVM model with the best hyperparameter (C=1)
vectorizer = TfidfVectorizer()
X_tfidf = vectorizer.fit_transform(X_train)
best_svm_model = SVC(kernel='linear', C=2)
best_svm_model.fit(X_tfidf, y_train)

#Get weights and features name
feature_names = vectorizer.get_feature_names_out()
coefficients = best_svm_model.coef_.toarray()[0]

coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})
sorted_coef_df = coef_df.sort_values(by='Coefficient', ascending=False)

#Find the top ten
top_positive_words = sorted_coef_df.head(10)
top_negative_words = sorted_coef_df.tail(10)

print("Top 10 words with the highest positive coefficients:")
print(top_positive_words)

print("\nTop 10 words with the highest negative coefficients:")
print(top_negative_words)

# Define the SVM model with RBF kernel
svm_rbf_model = SVC(kernel='rbf')

# Define the hyperparameter grid for grid search
param_grid = {'C': [10**i for i in range(-3,4)], 'gamma': [10**(-i) for i in range(-3,2)]}

# Perform grid search with cross-validation based on validation accuracy
grid_search_rbf = GridSearchCV(svm_rbf_model, param_grid, cv=3, scoring='accuracy')
grid_search_rbf.fit(X_train_tfidf, y_train)

# Get the best hyperparameters
best_params_rbf = grid_search_rbf.best_params_
best_c_rbf = best_params_rbf['C']
best_gamma_rbf = best_params_rbf['gamma']

# Train the SVM model with the best hyperparameters on the entire training set
final_svm_rbf_model = SVC(kernel='rbf', C=best_c_rbf, gamma=best_gamma_rbf)
final_svm_rbf_model.fit(X_train_tfidf, y_train)

total_support_vectors = final_svm_rbf_model.n_support_.sum()

y_val_pred_rbf = final_svm_rbf_model.predict(X_val_tfidf)
y_train_pred_rbf = final_svm_rbf_model.predict(X_train_tfidf)

# Evaluate the validation accuracy
val_accuracy_rbf = accuracy_score(y_val, y_val_pred_rbf)
train_accuracy_rbf = accuracy_score(y_train, y_train_pred_rbf)

print(f"Best C for RBF: {best_c_rbf}")
print(f"Best Gamma for RBF: {best_gamma_rbf}")
print(f"Validation Accuracy with RBF Kernel: {val_accuracy_rbf:.4f}")
print(f"Training Accuracy with RBF Kernel: {train_accuracy_rbf:.4f}")

# Your code go# Define the SVM model with RBF kernel
# Grid Refinement for Central Optima (1)

svm_rbf_model = SVC(kernel='rbf')

# Define the hyperparameter grid for grid search. We will do grid refindment around 10 and .1:
param_grid = {'C': [5,10,20,40,70], 'gamma': [.05,.1,.2,.5,.75]}

# Perform grid search with cross-validation based on validation accuracy
grid_search_rbf = GridSearchCV(svm_rbf_model, param_grid, cv=3, scoring='accuracy')
grid_search_rbf.fit(X_train_tfidf, y_train)

# Get the best hyperparameters
best_params_rbf = grid_search_rbf.best_params_
best_c_rbf = best_params_rbf['C']
best_gamma_rbf = best_params_rbf['gamma']

# Train the SVM model with the best hyperparameters on the entire training set
final_svm_rbf_model = SVC(kernel='rbf', C=best_c_rbf, gamma=best_gamma_rbf)
final_svm_rbf_model.fit(X_train_tfidf, y_train)

alpha_values = [2, 1, 0.5, 0.1, 0.05, 0.01]

train_accuracies = []
val_accuracies = []

for alpha in alpha_values:
    # Use TfidfVectorizer to convert text data to TF-IDF features
    vectorizer = TfidfVectorizer()
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_val_tfidf = vectorizer.transform(X_val)

    # Build a Multinomial Naive Bayes model with the specified alpha
    nb_model = MultinomialNB(alpha=alpha)

    # Train the model on the training set
    nb_model.fit(X_train_tfidf, y_train)

    # Make predictions on the validation set
    y_val_pred = nb_model.predict(X_val_tfidf)
    y_train_pred = nb_model.predict(X_train_tfidf)

    # Evaluate the accuracy on the validation set
    accuracy_val = accuracy_score(y_val, y_val_pred)
    accuracy_train = accuracy_score(y_train, y_train_pred)

    print(f"Validation Accuracy with Multinomial Naive Bayes (alpha={alpha}): {accuracy_val:.4f}")
    print(f"Training Accuracy with Multinomial Naive Bayes (alpha={alpha}): {accuracy_train:.4f}")
    val_accuracies.append(accuracy_val)
    train_accuracies.append(accuracy_train)

plt.figure(figsize=(10, 6))
plt.semilogx(alpha_values, train_accuracies, label='Training Accuracy', marker='o')
plt.semilogx(alpha_values, val_accuracies, label='Validation Accuracy', marker='o')

plt.title('Accuracy vs. Alpha')
plt.xlabel('Alpha (log scale)')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

alpha_values = [10 , 5, 2, 1.5, 1, 0.5, 0.1, 0.07, 0.05, 0.03, 0.01,.001,.0001]

for alpha in alpha_values:
    # Use TfidfVectorizer to convert text data to TF-IDF features
    vectorizer = TfidfVectorizer()
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_val_tfidf = vectorizer.transform(X_val)

    # Build a Multinomial Naive Bayes model with the specified alpha
    nb_model = MultinomialNB(alpha=alpha)

    # Train the model on the training set
    nb_model.fit(X_train_tfidf, y_train)

    # Make predictions on the validation set
    y_val_pred = nb_model.predict(X_val_tfidf)
    y_train_pred = nb_model.predict(X_train_tfidf)

    # Evaluate the accuracy on the validation set
    accuracy_val = accuracy_score(y_val, y_val_pred)
    accuracy_train = accuracy_score(y_train, y_train_pred)

    print(f"Validation Accuracy with Multinomial Naive Bayes (alpha={alpha}): {accuracy_val:.4f}")

alpha_1 = 1
alpha_0_03 = 0.03

nb_model_1 = MultinomialNB(alpha=alpha_1)
nb_model_0_03 = MultinomialNB(alpha=alpha_0_03)
nb_model_1.fit(X_tfidf, y_train)
nb_model_0_03.fit(X_tfidf, y_train)

feature_names = vectorizer.get_feature_names_out()

# Get the log probabilities for each feature in both models
log_probs_1 = nb_model_1.feature_log_prob_
log_probs_0_03 = nb_model_0_03.feature_log_prob_


sorted_indices_1 = log_probs_1.argsort(axis=1)[:, ::-1]
sorted_indices_0_03 = log_probs_0_03.argsort(axis=1)[:, ::-1]

# Print the top 10 words for each model
print("Top 10 words with the highest positive weights and their corresponding weights (alpha=1):")
for i in range(10):
    print(f"{feature_names[sorted_indices_1[1, i]]}: {log_probs_1[1, sorted_indices_1[1, i]]:.4f}")

print("\nTop 10 words with the highest negative weights and their corresponding weights (alpha=1):")
for i in range(10):
    print(f"{feature_names[sorted_indices_1[0, i]]}: {log_probs_1[0, sorted_indices_1[0, i]]:.4f}")

print("\nTop 10 words with the highest positive weights and their corresponding weights (alpha=0.03):")
for i in range(10):
    print(f"{feature_names[sorted_indices_0_03[1, i]]}: {log_probs_0_03[1, sorted_indices_0_03[1, i]]:.4f}")

print("\nTop 10 words with the highest negative weights and their corresponding weights (alpha=0.03):")
for i in range(10):
    print(f"{feature_names[sorted_indices_0_03[0, i]]}: {log_probs_0_03[0, sorted_indices_0_03[0, i]]:.4f}")
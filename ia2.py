# -*- coding: utf-8 -*-
"""IA2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-dNPiELCny2FFSC3HC7I_G7F15obtObn
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/gdrive')

train_path = '/content/gdrive/My Drive/AI534/IA2-train.csv'
val_path = '/content/gdrive/My Drive/AI534/IA2-dev.csv'
noisy_train_path = '/content/gdrive/My Drive/AI534/IA2-train-noisy.csv'

#get data paths into dataframes
train_data = pd.read_csv(train_path)
val_data = pd.read_csv(val_path)
noisy_train_data = pd.read_csv(noisy_train_path)

#Feature Normalization for training data
numerical = ["Age", "Annual_Premium", "Vintage"]
features = train_data[numerical]
categorical_features = train_data.drop(columns = numerical)
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
train_data_scaled_features = pd.DataFrame(scaled_features, columns=features.columns)
train_data_scaled = pd.concat([train_data_scaled_features, categorical_features], axis=1)


#Feature Normalization for validation data
numerical = ["Age", "Annual_Premium", "Vintage"]
features = val_data[numerical]
categorical_features = val_data.drop(columns = numerical)
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
val_data_scaled_features = pd.DataFrame(scaled_features, columns=features.columns)
val_data_scaled = pd.concat([val_data_scaled_features, categorical_features], axis=1)


#Feature Normalization for training data
numerical = ["Age", "Annual_Premium", "Vintage"]
features = noisy_train_data[numerical]
categorical_features = noisy_train_data.drop(columns = numerical)
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
noisy_train_data_scaled_features = pd.DataFrame(scaled_features, columns=features.columns)
noisy_train_data_scaled = pd.concat([noisy_train_data_scaled_features, categorical_features], axis=1)

#Create a function for logistic regression
x = train_data_scaled.drop(columns = "Response")
y = train_data_scaled["Response"]
def log_regression(x,y,lr,reg,num_sim, show_plot = True):
  x_values = x.values
  y_values = y.values

  #define the sigmoid function
  def sigmoid(x):
      return 1/(1+np.exp(-x))

  num_columns = x.shape[1]
  #initialize weight vector
  theta = np.random.randn(num_columns+1)
  #add intercept to weight vector
  column_of_ones = np.ones((x_values.shape[0],1), dtype=int)
  x_values = np.hstack((column_of_ones, x_values))

  #list of average cost
  cost = []
  #threshold for stopping early
  threshold = 1e-7

  for i in range(num_sim):
    #calculate the probabilities
    k = theta.dot(x_values.T)
    p = sigmoid(k)

    #computing the gradient of the cost function with L2
    gradient = (1/len(x_values))*x_values.T.dot(p-y_values)+(reg*theta)

    #Update the weights
    theta = theta - lr*gradient

    #calculate the cost function:
    cost_vector = list()
    for j in range(len(p)):
      if y[j] == 1:
        cost_vector.append(-(np.log(p[j])))
      else:
        cost_vector.append(-(np.log(1-p[j])))
    cost.append(np.mean(cost_vector))

    #stopping early if needed
    if i > 2 and abs(cost[-1] - cost[-2]) < threshold:
        print(f"Converged after {i} iterations.")
        break

  if show_plot:
    plt.plot(range(len(cost)), cost)
    plt.xlabel("Count")
    plt.ylabel("cost")
    plt.legend()

  #getting predictionos of final model to check the accuracy:
  prediction = []
  for i in range(len(p)):
    if p[i] >= .5:
      prediction.append(1)
    else:
      prediction.append(0)
  prediction = np.array(prediction)
  y_values = np.array(y_values)
  comparison_result = prediction == y_values
  accuracy = np.mean(comparison_result)
  return {"Weight Vector": theta, "Accuracy": accuracy, "Cost function": plt}
#call the function: Outputs should be final weight vector, graph of average cost over time and accuracy
log_regression(x,y,.001,.01,3000)

#define the validation features and response for the code:
val_x = val_data_scaled.drop(columns = "Response")
val_y = val_data_scaled["Response"]
#This function will return the results on validation data
def validation_test(val_x,val_y,x,y,lr,reg,num_sim):
  #call training model
  training_run = log_regression(x,y,lr,reg,num_sim, show_plot=False)

  final_weight_vetor = training_run["Weight Vector"]
  final_accuracy_train = training_run["Accuracy"]
  x_values = val_x.values
  y_values = val_y.values

  #define the sigmoid function
  def sigmoid(x):
      return 1/(1+np.exp(-x))

  num_columns = x.shape[1]
  #add intercept to inputs
  column_of_ones = np.ones((x_values.shape[0],1), dtype=int)
  x_values = np.hstack((column_of_ones, x_values))

  #calculate new predictions for validation data.
  k = final_weight_vetor.dot(x_values.T)
  p = sigmoid(k)

  prediction = []
  for i in range(len(p)):
    if p[i] >= .5:
      prediction.append(1)
    else:
      prediction.append(0)
  prediction = np.array(prediction)
  y_values = np.array(y_values)
  comparison_result = prediction == y_values
  accuracy = np.mean(comparison_result)

  return {"Training Accuracy": final_accuracy_train, "Validation Accuracy": accuracy, "Weight Vector":final_weight_vetor}

validation_test(val_x,val_y, x, y, .01, .001, 3000)

num_sims = 3000
#learning rate = 1, regularization parameter = 10^-5
validation_lambda_five = validation_test(val_x,val_y, x, y, 1, .00001, num_sims)
#learning rate = 1 regularization parameter = 10^-4
validation_lambda_four = validation_test(val_x,val_y, x, y, 1, .0001, num_sims)
#learning rate = .1, regularization parameter = 10^-3
validation_lambda_three = validation_test(val_x,val_y, x, y, .1, .001, num_sims)
#learning rate = .01, regularization parameter = 10^-2
validation_lambda_two = validation_test(val_x,val_y, x, y, .01, .01, num_sims)
#learning rate = .01, regularization parameter = 10^-1
validation_lambda_one = validation_test(val_x,val_y, x, y, .01, .1, num_sims)
#learning rate = .01, regularization parameter = 10^0
validation_lambda_zero = validation_test(val_x,val_y, x, y, .001, 1, num_sims)

print("Lambda = 10^0:", validation_lambda_zero)
print("Lambda = 10^-1:", validation_lambda_one)
print("Lambda = 10^-2:", validation_lambda_two)
print("Lambda = 10^-3:", validation_lambda_three)
print("Lambda = 10^-4:", validation_lambda_four)
print("Lambda = 10^-5:", validation_lambda_five )

training_accuracy_zero = validation_lambda_zero["Training Accuracy"]
training_accuracy_one = validation_lambda_one["Training Accuracy"]
training_accuracy_two = validation_lambda_two["Training Accuracy"]
training_accuracy_three = validation_lambda_three["Training Accuracy"]
training_accuracy_four = validation_lambda_four["Training Accuracy"]
training_accuracy_five = validation_lambda_five["Training Accuracy"]

validation_accuracy_zero = validation_lambda_zero["Validation Accuracy"]
validation_accuracy_one = validation_lambda_one["Validation Accuracy"]
validation_accuracy_two = validation_lambda_two["Validation Accuracy"]
validation_accuracy_three = validation_lambda_three["Validation Accuracy"]
validation_accuracy_four = validation_lambda_four["Validation Accuracy"]
validation_accuracy_five = validation_lambda_five["Validation Accuracy"]

#for plotting purpose only
lambda_values = [0, 1, 2, 3, 4, 5]

training_accuracy = [
    training_accuracy_zero,
    training_accuracy_one,
    training_accuracy_two,
    training_accuracy_three,
    training_accuracy_four,
    training_accuracy_five
]

validation_accuracy = [
    validation_accuracy_zero,
    validation_accuracy_one,
    validation_accuracy_two,
    validation_accuracy_three,
    validation_accuracy_four,
    validation_accuracy_five
]

# Create the line plot
plt.figure(figsize=(8, 5))
plt.plot(lambda_values, training_accuracy, marker='o', linestyle='-', color='blue', label='Training')
plt.plot(lambda_values, validation_accuracy, marker='s', linestyle='-', color='green', label='Validation')
custom_ticks = [0, 1, 2, 3, 4, 5]
custom_labels = ['1', '1e-1', '1e-2', '1e-3', '1e-4', '1e-5']
plt.title("Training and Validation Accuracy vs. Lambda")
plt.xlabel("Lambda")
plt.ylabel("Accuracy")
plt.xticks(custom_ticks, custom_labels)
plt.grid(True)
plt.legend()
plt.show()

print(training_accuracy)
print(validation_accuracy)

#Get the column names
column_names = train_data.columns
column_names_list = column_names.tolist()

num_sims = 3000

#Finding what weights are the largest
lambda_zero_p1 = validation_lambda_zero["Weight Vector"]
five_largest_zero_p1 = np.argsort(-lambda_zero_p1)[:5]
#getting the names of the largest feature
selected_column_names_zero = [column_names_list[i] for i in five_largest_zero_p1]
selected_column_weights_zero = [lambda_zero_p1[i] for i in five_largest_zero_p1]

#Finding what weights are the largest
lambda_one_p1 = validation_lambda_one["Weight Vector"]
five_largest_one_p1 = np.argsort(-lambda_one_p1)[:5]
#getting the names of the largest feature
selected_column_names_one = [column_names_list[i] for i in five_largest_one_p1]
selected_column_weights_one = [lambda_one[i] for i in five_largest_one_p1]

#Finding what weights are the largest
lambda_two_p1 = validation_lambda_two["Weight Vector"]
five_largest_two_p1 = np.argsort(-lambda_two_p1)[:5]
#getting the names of the largest feature
selected_column_names_two = [column_names_list[i] for i in five_largest_two_p1]
selected_column_weights_two = [lambda_two_p1[i] for i in five_largest_two_p1]

#Finding what weights are the largest
lambda_three_p1 = validation_lambda_three["Weight Vector"]
five_largest_three_p1 = np.argsort(-lambda_three_p1)[:5]
#getting the names of the largest feature
selected_column_names_three = [column_names_list[i] for i in five_largest_three_p1]
selected_column_weights_three = [lambda_three_p1[i] for i in five_largest_three_p1]

#Finding what weights are the largest
lambda_four_p1 = validation_lambda_four["Weight Vector"]
five_largest_four_p1 = np.argsort(-lambda_four_p1)[:5]
#getting the names of the largest feature
selected_column_names_four = [column_names_list[i] for i in five_largest_four_p1]
selected_column_weights_four = [lambda_four_p1[i] for i in five_largest_four_p1]

#Finding what weights are the largest
lambda_five_p1 = validation_lambda_five["Weight Vector"]
five_largest_five_p1 = np.argsort(-lambda_five_p1)[:5]
#getting the names of the largest feature
selected_column_names_five = [column_names_list[i] for i in five_largest_five_p1]
selected_column_weights_five = [lambda_five_p1[i] for i in five_largest_five_p1]

data = {
    "lambda = 10^0": selected_column_names_zero,
    'weight for lambda = 10^0': selected_column_weights_zero,
    "lambda = 10^-1": selected_column_names_one,
    'weight for lambda = 10^-1': selected_column_weights_one,
    "lambda = 10^-2": selected_column_names_two,
    'weight for lambda = 10^-2': selected_column_weights_two,
    "lambda = 10^-3": selected_column_names_three,
    'weight for lambda = 10^-3': selected_column_weights_three,
    "lambda = 10^-4": selected_column_names_four,
    'weight for lambda = 10^-4': selected_column_weights_four,
    "lambda = 10^-5": selected_column_names_five,
    'weight for lambda = 10^-5': selected_column_weights_five
}

df = pd.DataFrame(data)

print(df)

#We will use the same weight vectors that were computed in 1.2
count_zero = sum(1 for value in lambda_zero if value < 1e-6)
count_one = sum(1 for value in lambda_one if value < 1e-6)
count_two = sum(1 for value in lambda_two if value < 1e-6)
count_three = sum(1 for value in lambda_three if value < 1e-6)
count_four = sum(1 for value in lambda_four if value < 1e-6)
count_five = sum(1 for value in lambda_five if value < 1e-6)
print("Lambda = 10^0:", count_zero)
print("Lambda = 10^-1:", count_one)
print("Lambda = 10^-2:", count_two)
print("Lambda = 10^-3:", count_three)
print("Lambda = 10^-4:", count_four)
print("Lambda = 10^-5:", count_five)

def log_regressionL1(x,y,lr,reg,num_sim,show_plot=True):
  x_values = x.values
  y_values = y.values

  #define the sigmoid function
  def sigmoid(x):
      return 1/(1+np.exp(-x))

  num_columns = x.shape[1]
  #initialize weight vector
  theta = np.random.randn(num_columns+1)
  #add intercept to weight vector
  column_of_ones = np.ones((x_values.shape[0],1), dtype=int)
  x_values = np.hstack((column_of_ones, x_values))

  #list of average cost
  cost = []
  #threshold for stopping early
  threshold = 1e-7

  for i in range(num_sim):
    #calculate the probabilities
    k = theta.dot(x_values.T)
    p = sigmoid(k)

    #computing the gradient of the cost function with L1:
    gradient = (1/len(x_values))*x_values.T.dot(p-y_values)+(reg*np.sign(theta))

    #Update the weights
    theta = theta - lr*gradient

    #calculate the cost function:
        #calculate the cost function:
    cost_vector = list()
    for j in range(len(p)):
      if y[j] == 1:
        cost_vector.append(-(np.log(p[j])))
      else:
        cost_vector.append(-(np.log(1-p[j])))
    cost.append(np.mean(cost_vector))

    #stopping early if needed
    if i > 2 and abs(cost[-1] - cost[-2]) < threshold:
        print(f"Converged after {i} iterations.")
        break

  if show_plot:
    plt.plot(range(len(cost)), cost)
    plt.xlabel("Count")
    plt.ylabel("cost")
    plt.legend()

  #getting predictionos of final model to check the accuracy:
  prediction = []
  for i in range(len(p)):
    if p[i] >= .5:
      prediction.append(1)
    else:
      prediction.append(0)
  prediction = np.array(prediction)
  y_values = np.array(y_values)
  comparison_result = prediction == y_values
  accuracy = np.mean(comparison_result)
  return {"Weight Vector": theta, "Accuracy": accuracy, "Cost function": plt}

log_regressionL1(x,y,1,.001,3000)

#define the validation features and response for the code:
val_x = val_data_scaled.drop(columns = "Response")
val_y = val_data_scaled["Response"]
#This function will return the results on validation data
def validation_testL1(val_x,val_y,x,y,lr,reg,num_sim):
  #call training model
  training_run = log_regression(x,y,lr,reg,num_sim, show_plot=False)

  final_weight_vetor = training_run["Weight Vector"]
  final_accuracy_train = training_run["Accuracy"]
  x_values = val_x.values
  y_values = val_y.values

  #define the sigmoid function
  def sigmoid(x):
      return 1/(1+np.exp(-x))

  num_columns = x.shape[1]
  #add intercept to inputs
  column_of_ones = np.ones((x_values.shape[0],1), dtype=int)
  x_values = np.hstack((column_of_ones, x_values))

  #calculate new predictions for validation data.
  k = final_weight_vetor.dot(x_values.T)
  p = sigmoid(k)

  prediction = []
  for i in range(len(p)):
    if p[i] >= .5:
      prediction.append(1)
    else:
      prediction.append(0)
  prediction = np.array(prediction)
  y_values = np.array(y_values)
  comparison_result = prediction == y_values
  accuracy = np.mean(comparison_result)

  return {"Training Accuracy": final_accuracy_train, "Validation Accuracy": accuracy, "Weight Vector":final_weight_vetor}

validation_testL1(val_x,val_y, x, y, .01, .001, 3000)

num_sims = 3000
#learning rate = 1, regularization parameter = 10^-6
validation_lambda_five = validation_testL1(val_x,val_y, x, y, 2, .000001, num_sims)
#learning rate = 1, regularization parameter = 10^-5
validation_lambda_four = validation_testL1(val_x,val_y, x, y, 2, .00001, num_sims)
#learning rate = 1 regularization parameter = 10^-4
validation_lambda_three = validation_testL1(val_x,val_y, x, y, 1, .0001, num_sims)
#learning rate = .1, regularization parameter = 10^-3
validation_lambda_two = validation_testL1(val_x,val_y, x, y, .1, .001, num_sims)
#learning rate = .01, regularization parameter = 10^-2
validation_lambda_one = validation_testL1(val_x,val_y, x, y, .01, .01, num_sims)
#learning rate = .01, regularization parameter = 10^-1
validation_lambda_zero = validation_testL1(val_x,val_y, x, y, .01, .1, num_sims)

print("Lambda = 10^0:", validation_lambda_zero)
print("Lambda = 10^-1:", validation_lambda_one)
print("Lambda = 10^-2:", validation_lambda_two)
print("Lambda = 10^-3:", validation_lambda_three)
print("Lambda = 10^-4:", validation_lambda_four)
print("Lambda = 10^-5:", validation_lambda_five )

training_accuracy_zero = validation_lambda_zero["Training Accuracy"]
training_accuracy_one = validation_lambda_one["Training Accuracy"]
training_accuracy_two = validation_lambda_two["Training Accuracy"]
training_accuracy_three = validation_lambda_three["Training Accuracy"]
training_accuracy_four = validation_lambda_four["Training Accuracy"]
training_accuracy_five = validation_lambda_five["Training Accuracy"]

validation_accuracy_zero = validation_lambda_zero["Validation Accuracy"]
validation_accuracy_one = validation_lambda_one["Validation Accuracy"]
validation_accuracy_two = validation_lambda_two["Validation Accuracy"]
validation_accuracy_three = validation_lambda_three["Validation Accuracy"]
validation_accuracy_four = validation_lambda_four["Validation Accuracy"]
validation_accuracy_five = validation_lambda_five["Validation Accuracy"]

#for plotting purpose only
lambda_values = [0, 1, 2, 3, 4, 5]

training_accuracy = [
    training_accuracy_zero,
    training_accuracy_one,
    training_accuracy_two,
    training_accuracy_three,
    training_accuracy_four,
    training_accuracy_five
]

validation_accuracy = [
    validation_accuracy_zero,
    validation_accuracy_one,
    validation_accuracy_two,
    validation_accuracy_three,
    validation_accuracy_four,
    validation_accuracy_five
]

# Create the line plot
plt.figure(figsize=(8, 5))
plt.plot(lambda_values, training_accuracy, marker='o', linestyle='-', color='blue', label='Training')
plt.plot(lambda_values, validation_accuracy, marker='s', linestyle='-', color='green', label='Validation')
custom_ticks = [0, 1, 2, 3, 4, 5]
custom_labels = ['1e-1', '1e-2', '1e-3', '1e-4', '1e-5', '1e-6']
plt.title("Training and Validation Accuracy vs. Lambda")
plt.xlabel("Lambda")
plt.ylabel("Accuracy")
plt.xticks(custom_ticks, custom_labels)
plt.grid(True)
plt.legend()
plt.show()

print(training_accuracy)
print(validation_accuracy)

num_sims = 3000

#Finding what weights are the largest
lambda_zero_p2 = validation_lambda_zero["Weight Vector"]
five_largest_zero_p2 = np.argsort(-lambda_zero_p2)[:5]
#getting the names of the largest feature
selected_column_names_zero_p2 = [column_names_list[i] for i in five_largest_zero_p2]
selected_column_weights_zero_p2 = [lambda_zero_p2[i] for i in five_largest_zero_p2]

#Finding what weights are the largest
lambda_one_p2 = validation_lambda_one["Weight Vector"]
five_largest_one_p2 = np.argsort(-lambda_one_p2)[:5]
#getting the names of the largest feature
selected_column_names_one_p2 = [column_names_list[i] for i in five_largest_one_p2]
selected_column_weights_one_p2 = [lambda_zero_p2[i] for i in five_largest_one_p2]

#Finding what weights are the largest
lambda_two_p2 = validation_lambda_two["Weight Vector"]
five_largest_two_p2 = np.argsort(-lambda_two_p2)[:5]
#getting the names of the largest feature
selected_column_names_two_p2 = [column_names_list[i] for i in five_largest_two_p2]
selected_column_weights_two_p2 = [lambda_zero_p2[i] for i in five_largest_two_p2]

#Finding what weights are the largest
lambda_three_p2 = validation_lambda_three["Weight Vector"]
five_largest_three_p2 = np.argsort(-lambda_three_p2)[:5]
#getting the names of the largest feature
selected_column_names_three_p2 = [column_names_list[i] for i in five_largest_three_p2]
selected_column_weights_three_p2 = [lambda_zero_p2[i] for i in five_largest_three_p2]

#Finding what weights are the largest
lambda_four_p2 = validation_lambda_four["Weight Vector"]
five_largest_four_p2 = np.argsort(-lambda_four_p2)[:5]
#getting the names of the largest feature
selected_column_names_four_p2 = [column_names_list[i] for i in five_largest_four_p2]
selected_column_weights_four_p2 = [lambda_zero_p2[i] for i in five_largest_four_p2]

#Finding what weights are the largest
lambda_five_p2 = validation_lambda_five["Weight Vector"]
five_largest_five_p2 = np.argsort(-lambda_five_p2)[:5]
#getting the names of the largest feature
selected_column_names_five_p2 = [column_names_list[i] for i in five_largest_five_p2]
selected_column_weights_five_p2 = [lambda_zero_p2[i] for i in five_largest_five_p2]

data = {
    "lambda = 10^-1": selected_column_names_zero_p2,
    "weights for lambda = 10^-1": selected_column_weights_zero_p2,
    "lambda = 10^-2": selected_column_names_one_p2,
    "weights for lambda = 10^-2": selected_column_weights_one_p2,
    "lambda = 10^-3": selected_column_names_two_p2,
    "weights for lambda = 10^-3": selected_column_weights_two_p2,
    "lambda = 10^-4": selected_column_names_three_p2,
    "weights for lambda = 10^-4": selected_column_weights_three_p2,
    "lambda = 10^-5": selected_column_names_four_p2,
    "weights for lambda = 10^-5": selected_column_weights_four_p2,
    "lambda = 10^-6": selected_column_names_five_p2,
    "weights for lambda = 10^-6": selected_column_weights_five_p2,
}

df = pd.DataFrame(data)

print(df)

#We will use the same weight vectors that were computed in 2.2
count_zero = sum(1 for value in lambda_zero if value < 1e-6)
count_one = sum(1 for value in lambda_one if value < 1e-6)
count_two = sum(1 for value in lambda_two if value < 1e-6)
count_three = sum(1 for value in lambda_three if value < 1e-6)
count_four = sum(1 for value in lambda_four if value < 1e-6)
count_five = sum(1 for value in lambda_five if value < 1e-6)
print("Lambda = 10^0:", count_zero)
print("Lambda = 10^-1:", count_one)
print("Lambda = 10^-2:", count_two)
print("Lambda = 10^-3:", count_three)
print("Lambda = 10^-4:", count_four)
print("Lambda = 10^-5:", count_five)

x2 = noisy_train_data_scaled.drop(columns = "Response")
y2 = noisy_train_data_scaled["Response"]

#This is for L2
num_sims = 3000
#learning rate = 1, regularization parameter = 10^-5
validation_lambda_five = validation_test(val_x,val_y, x2, y2, 1, .00001, num_sims)
#learning rate = 1 regularization parameter = 10^-4
validation_lambda_four = validation_test(val_x,val_y, x2, y2, 1, .0001, num_sims)
#learning rate = .1, regularization parameter = 10^-3
validation_lambda_three = validation_test(val_x,val_y, x2, y2, .1, .001, num_sims)
#learning rate = .01, regularization parameter = 10^-2
validation_lambda_two = validation_test(val_x,val_y, x2, y2, .01, .01, num_sims)
#learning rate = .01, regularization parameter = 10^-1
validation_lambda_one = validation_test(val_x,val_y, x2, y2, .01, .1, num_sims)
#learning rate = .01, regularization parameter = 10^0
validation_lambda_zero = validation_test(val_x,val_y, x2, y2, .001, 1, num_sims)

training_accuracy_zero = validation_lambda_zero["Training Accuracy"]
training_accuracy_one = validation_lambda_one["Training Accuracy"]
training_accuracy_two = validation_lambda_two["Training Accuracy"]
training_accuracy_three = validation_lambda_three["Training Accuracy"]
training_accuracy_four = validation_lambda_four["Training Accuracy"]
training_accuracy_five = validation_lambda_five["Training Accuracy"]

validation_accuracy_zero = validation_lambda_zero["Validation Accuracy"]
validation_accuracy_one = validation_lambda_one["Validation Accuracy"]
validation_accuracy_two = validation_lambda_two["Validation Accuracy"]
validation_accuracy_three = validation_lambda_three["Validation Accuracy"]
validation_accuracy_four = validation_lambda_four["Validation Accuracy"]
validation_accuracy_five = validation_lambda_five["Validation Accuracy"]

#for plotting purpose only
lambda_values = [0, 1, 2, 3, 4, 5]

training_accuracy = [
    training_accuracy_zero,
    training_accuracy_one,
    training_accuracy_two,
    training_accuracy_three,
    training_accuracy_four,
    training_accuracy_five
]

validation_accuracy = [
    validation_accuracy_zero,
    validation_accuracy_one,
    validation_accuracy_two,
    validation_accuracy_three,
    validation_accuracy_four,
    validation_accuracy_five
]

# Create the line plot
plt.figure(figsize=(8, 5))
plt.plot(lambda_values, training_accuracy, marker='o', linestyle='-', color='blue', label='Training')
plt.plot(lambda_values, validation_accuracy, marker='s', linestyle='-', color='green', label='Validation')
custom_ticks = [0, 1, 2, 3, 4, 5]
custom_labels = ['1','1e-1', '1e-2', '1e-3', '1e-4', '1e-5']
plt.title("Training and Validation Accuracy vs. Lambda")
plt.xlabel("Lambda")
plt.ylabel("Accuracy")
plt.xticks(custom_ticks, custom_labels)
plt.grid(True)
plt.legend()
plt.show()

print(training_accuracy)
print(validation_accuracy)

#This is for L1
num_sims = 3000
#learning rate = 1, regularization parameter = 10^-6
validation_lambda_five = validation_testL1(val_x,val_y, x2, y2, 2, .000001, num_sims)
#learning rate = 1, regularization parameter = 10^-5
validation_lambda_four = validation_testL1(val_x,val_y, x2, y2, 2, .00001, num_sims)
#learning rate = 1 regularization parameter = 10^-4
validation_lambda_three = validation_testL1(val_x,val_y, x2, y2, 1, .0001, num_sims)
#learning rate = .1, regularization parameter = 10^-3
validation_lambda_two = validation_testL1(val_x,val_y, x2, y2, .1, .001, num_sims)
#learning rate = .01, regularization parameter = 10^-2
validation_lambda_one = validation_testL1(val_x,val_y, x2, y2, .01, .01, num_sims)

training_accuracy_one = validation_lambda_one["Training Accuracy"]
training_accuracy_two = validation_lambda_two["Training Accuracy"]
training_accuracy_three = validation_lambda_three["Training Accuracy"]
training_accuracy_four = validation_lambda_four["Training Accuracy"]
training_accuracy_five = validation_lambda_five["Training Accuracy"]

validation_accuracy_one = validation_lambda_one["Validation Accuracy"]
validation_accuracy_two = validation_lambda_two["Validation Accuracy"]
validation_accuracy_three = validation_lambda_three["Validation Accuracy"]
validation_accuracy_four = validation_lambda_four["Validation Accuracy"]
validation_accuracy_five = validation_lambda_five["Validation Accuracy"]

#for plotting purpose only
lambda_values = [1, 2, 3, 4, 5]

training_accuracy = [
    training_accuracy_one,
    training_accuracy_two,
    training_accuracy_three,
    training_accuracy_four,
    training_accuracy_five
]

validation_accuracy = [
    validation_accuracy_one,
    validation_accuracy_two,
    validation_accuracy_three,
    validation_accuracy_four,
    validation_accuracy_five
]

# Create the line plot
plt.figure(figsize=(8, 5))
plt.plot(lambda_values, training_accuracy, marker='o', linestyle='-', color='blue', label='Training')
plt.plot(lambda_values, validation_accuracy, marker='s', linestyle='-', color='green', label='Validation')
custom_ticks = [1, 2, 3, 4, 5]
custom_labels = ['1e-2', '1e-3', '1e-4', '1e-5', '1e-6']
plt.title("Training and Validation Accuracy vs. Lambda")
plt.xlabel("Lambda")
plt.ylabel("Accuracy")
plt.xticks(custom_ticks, custom_labels)
plt.grid(True)
plt.legend()
plt.show()

print("Training:", training_accuracy)
print("Validaiotn:", validation_accuracy)